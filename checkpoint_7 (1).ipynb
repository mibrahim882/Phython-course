{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1NE4ed0PJp_"
      },
      "outputs": [],
      "source": [
        "#1.1\n",
        "from requests_html import HTMLSession\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "ht = HTMLSession()\n",
        "url = \"https://en.wikipedia.org/wiki/Egypt\"\n",
        "\n",
        "def data(url):\n",
        "  gt = ht.get(url)\n",
        "  soup = BeautifulSoup(gt.text, 'html.parser')\n",
        "  return soup\n",
        "soup = data(url)\n",
        "print(soup)  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.2\n",
        "def title(soup):\n",
        "  titles = soup.find(\"title\")\n",
        "  return titles\n",
        "print(title(soup))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxgfZItzUClG",
        "outputId": "796da98b-a8bf-46ce-d93a-609c2aff9b0e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<title>Egypt - Wikipedia</title>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.3\n",
        "def paragraphs():\n",
        "  for head in soup.find_all(\"p\"):\n",
        "    print(head.get_text())\n",
        "paragraphs()    "
      ],
      "metadata": {
        "id": "94Ie61i6ZY2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1.4\n",
        "def links():\n",
        "  links = {}\n",
        "  for link in soup.find_all(\"a\"):\n",
        "    url = link.get(\"href\", \"\")\n",
        "    if \"/wiki/\" in url:\n",
        "      links[link.text.strip()] = url\n",
        "print(links)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY1jLgJ5cQyQ",
        "outputId": "bd7f5cb1-f94f-4aa1-c2e3-340094290513"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function links at 0x7f23cda1ee60>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.5\n",
        "from requests_html import HTMLSession\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "ht = HTMLSession()\n",
        "url = \"https://en.wikipedia.org/wiki/Egypt\"\n",
        "\n",
        "def data(url):\n",
        "  gt = ht.get(url)\n",
        "  soup = BeautifulSoup(gt.text, 'html.parser')\n",
        "  return soup\n",
        "soup = data(url)\n",
        "print(soup) \n",
        "\n",
        "def title(soup):\n",
        "  titles = soup.find(\"title\")\n",
        "  return titles\n",
        "print(title(soup)) \n",
        "\n",
        "def paragraphs():\n",
        "  for head in soup.find_all(\"p\"):\n",
        "    print(head.get_text())\n",
        "paragraphs()    \n",
        "def links():\n",
        "  links = {}\n",
        "  for link in soup.find_all(\"a\"):\n",
        "    url = link.get(\"href\", \"\")\n",
        "    if \"/wiki/\" in url:\n",
        "      links[link.text.strip()] = url\n",
        "print(links)"
      ],
      "metadata": {
        "id": "HcgjQdyegXdD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}